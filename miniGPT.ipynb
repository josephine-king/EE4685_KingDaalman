{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EE4685 Assignment 2: Building a miniGPT** by Josephine King and Alec Daalman\n",
    "\n",
    "**References:**\n",
    "- \"Let's build GPT: from scratch, in code, spelled out.\" Youtube tutorial by Andrej Karpathy. https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "- HuggingFace Tokenizer developer guides. https://huggingface.co/docs/transformers/en/notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data\n",
    "from tokenizers import Tokenizer, pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from torchmetrics.text import Perplexity\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "# Setup\n",
    "torch.manual_seed(6250513)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CHECKPOINT_PATH = \"./saved_models2/\"\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "# Initialize model parameters\n",
    "TRAIN_PCT = 0.8\n",
    "BLOCK_SIZE = 64\n",
    "BATCH_SIZE = 32\n",
    "MAX_ITER = 1500\n",
    "VOCAB_SIZE = 3000\n",
    "EMBD_DIM = 192\n",
    "NUM_DECODERS = 5\n",
    "NUM_HEADS = 12\n",
    "LR = 2.5e-5\n",
    "\n",
    "# Download the TinyShakespeare dataset\n",
    "!wget -O tinyshakespeare.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('tinyshakespeare.txt', 'r', encoding='utf-8') as f: raw_data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bigram Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from Karpathy's tutorial\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # Generate num_gen_tokens more tokens given the current tokens in curr_tokens\n",
    "    def generate(self, curr_tokens, num_gen_tokens):\n",
    "        for _ in range(num_gen_tokens):\n",
    "            # Get the predictions for the next tokens \n",
    "            preds, loss = self.forward(curr_tokens)\n",
    "            # Look only at the last time step\n",
    "            preds = preds[:, -1, :] # becomes (B, C)\n",
    "            # Normalize probabilities from 0 to 1 using softmax\n",
    "            probs = F.softmax(preds, dim=-1) # (B, C)\n",
    "            # Get the next token by sampling from the probability distribution\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # Add the new token to the current tokens\n",
    "            curr_tokens = torch.cat((curr_tokens, next_token), dim=1) # (B, T+1)\n",
    "        return curr_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPT Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT architecture \n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, block_size, batch_size, embd_dim, decoders, num_heads):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embd_dim)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, embd_dim)\n",
    "\n",
    "        self.transformer_blocks = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=embd_dim, nhead=num_heads, dim_feedforward=3072, dropout=0.1), decoders, norm=None)\n",
    "        self.linear_layer = nn.Linear(embd_dim, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "        self.config = {\"vocab_size\": vocab_size, \"block_size\": block_size, \"batch_size\": batch_size, \"embd_dim\": embd_dim, \"decoders\": decoders, \"num_heads\": num_heads}\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        B, T = idx.shape\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        inputs = tok_emb + pos_emb # (B,T,C)\n",
    "        inputs = self.transformer_blocks(inputs, memory=torch.zeros_like(inputs))\n",
    "        logits = self.linear_layer(inputs)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # Generate num_gen_tokens more tokens given the current tokens in curr_tokens\n",
    "    def generate(self, curr_tokens, num_gen_tokens):\n",
    "        for _ in range(num_gen_tokens):\n",
    "            curr_tokens_cond = curr_tokens[:, -self.block_size:]\n",
    "            # Get the predictions for the next tokens \n",
    "            preds, loss = self.forward(curr_tokens_cond)\n",
    "            # Look only at the last time step\n",
    "            preds = preds[:, -1, :] # becomes (B, C)\n",
    "            # Normalize probabilities from 0 to 1 using softmax\n",
    "            probs = F.softmax(preds, dim=-1) # (B, C)\n",
    "            # Get the next token by sampling from the probability distribution\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # Add the new token to the current tokens\n",
    "            curr_tokens = torch.cat((curr_tokens, next_token), dim=1) # (B, T+1)\n",
    "        return curr_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Evaluation Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model, data, batch_size, block_size, iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    losses = torch.zeros(iters)\n",
    "    for k in range(iters):\n",
    "        inputs, outputs = get_batch(data, batch_size, block_size)\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(inputs, outputs)\n",
    "        losses[k] = loss.item()\n",
    "    mean_loss = losses.mean()\n",
    "    model.train()\n",
    "    return mean_loss\n",
    "\n",
    "def calculate_perplexity(model, validation_data, num_batch, batch_size, block_size):\n",
    "    perplexities = []\n",
    "    for i in range(0, num_batch):\n",
    "        inputs, outputs = get_batch(validation_data, batch_size, block_size)\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(inputs)\n",
    "\n",
    "        perplexity = Perplexity().to(device)\n",
    "        score = perplexity(preds=logits[:, :-1], target=inputs[:, 1:]) \n",
    "        perplexities.append(score.item())\n",
    "\n",
    "    return np.mean(perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size, block_size):\n",
    "    # Choose batch_size random starting points\n",
    "    block_starts = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    # Get the inputs and outputs for the chosen blocks, stack them into tensors\n",
    "    batch_inputs = torch.stack([data[start: start + block_size] for start in block_starts])\n",
    "    batch_outputs = torch.stack([data[start + 1: start + block_size + 1] for start in block_starts])\n",
    "    return batch_inputs, batch_outputs\n",
    "\n",
    "# The following functions are adapted from the optimization exercise \n",
    "def _get_config_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \".config\")\n",
    "\n",
    "def _get_model_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \".tar\")\n",
    "\n",
    "def _get_result_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \"_results.json\")\n",
    "\n",
    "def save_model(model, model_path, model_name, model_result):\n",
    "    config_dict = model.config\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    config_file, model_file, result_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name), _get_result_file(model_path, model_name)\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config_dict, f)\n",
    "    with open(result_file, \"w\") as f:\n",
    "        json.dump(model_result, f)\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_path, model_name):\n",
    "    config_file, model_file, result_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name), _get_result_file(model_path, model_name)\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "\n",
    "    model = GPT(config_dict[\"vocab_size\"], config_dict[\"block_size\"], config_dict[\"batch_size\"], config_dict[\"embd_dim\"], config_dict[\"decoders\"], config_dict[\"num_heads\"])\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device(device)))    \n",
    "    \n",
    "    with open(result_file, \"r\") as f:\n",
    "        model_result = json.load(f)\n",
    "\n",
    "    return model, model_result\n",
    "\n",
    "def train_model(train_set, validation_set, model, model_name, optimizer, max_iter=1000, batch_size=256, block_size=32, overwrite=False, savemodel=False):\n",
    "    \"\"\"\n",
    "    Train a model on the training set of FashionMNIST\n",
    "\n",
    "    Inputs:\n",
    "        train_set - Training dataset\n",
    "        validation_set - Validation dataset\n",
    "        model - nn.Module object\n",
    "        model_name - Name of the model\n",
    "        max_iter - Number of iterations we want to (maximally) train for\n",
    "        batch_size - Size of batches used in training\n",
    "        overwrite - Determines if we should overwrite pre-existing models\n",
    "        savemodel - Whether or not we should save the model to a file\n",
    "    \"\"\"\n",
    "    # Check if the model already exists\n",
    "    # If it does and we are not overwriting, load it from the file\n",
    "    # If it doesn't, train the model\n",
    "    file_exists = os.path.isfile(_get_model_file(CHECKPOINT_PATH, model_name))\n",
    "    if file_exists and not overwrite:\n",
    "        print(f\"Model file of \\\"{model_name}\\\" already exists. Skipping training...\")\n",
    "        model, results = load_model(CHECKPOINT_PATH, model_name)\n",
    "    else:\n",
    "        if file_exists:\n",
    "            print(\"Model file exists, but will be overwritten...\")\n",
    "\n",
    "        # Training the model\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        iters = []\n",
    "        results = {}\n",
    "        model.train()\n",
    "        for iter in range(max_iter):\n",
    "            inputs, outputs = get_batch(train_set, batch_size, block_size)\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds,loss = model(inputs, outputs)\n",
    "\n",
    "            # Printing \n",
    "            if iter % 500 == 0 or iter == max_iter - 1:\n",
    "                print(f\"iter {iter}: loss = {loss}\")\n",
    "\n",
    "            # Estimate and save the training loss and validation loss\n",
    "            if (iter % 100 == 0):\n",
    "                training_loss = estimate_loss(model, train_set, batch_size, block_size, 500)\n",
    "                validation_loss = estimate_loss(model, validation_set, batch_size, block_size, 500)\n",
    "                training_losses.append(training_loss.item())\n",
    "                validation_losses.append(validation_loss.item())\n",
    "                iters.append(iter)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the perplexity and save results to the dict\n",
    "        perplexity = calculate_perplexity(model, validation_set, 500, batch_size, block_size)\n",
    "        results[\"perplexity\"] = perplexity\n",
    "        results[\"iters\"] = iters\n",
    "        results[\"training_loss\"] = training_losses\n",
    "        results[\"validation_loss\"] = validation_losses\n",
    "\n",
    "        # Save the model to a file\n",
    "        if (savemodel):\n",
    "            save_model(model, CHECKPOINT_PATH, model_name, results)\n",
    "\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n",
    "\n",
    "Create a custom tokenizer using the HuggingFace Tokenizer package. Then encode the data, convert it into a PyTorch tensor, and split it up into validation data and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tokenizer \n",
    "def train_tokenizer(train_file_name, save_file_name, vocab_size):\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\")) \n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(\"isolated\"), pre_tokenizers.Split(\"\\n\", \"isolated\"), pre_tokenizers.Split(\" \", \"isolated\")])\n",
    "    trainer = BpeTrainer(vocab_size=vocab_size)\n",
    "    tokenizer.decoder = BPEDecoder()\n",
    "    tokenizer.train([train_file_name], trainer)\n",
    "    tokenizer.save(save_file_name)\n",
    "    return tokenizer\n",
    "\n",
    "# Load a pre-existing tokenizer\n",
    "def load_tokenizer(file_name):\n",
    "    tokenizer = Tokenizer.from_file(file_name)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_data(tokenizer, raw_data, train_pct):\n",
    "    tokenized_data = tokenizer.encode(raw_data).ids\n",
    "    # Convert into a pytorch tensor\n",
    "    tensor_data = torch.tensor(tokenized_data, dtype=torch.long)\n",
    "    # Split into training and validation sets\n",
    "    train_end = int(len(tensor_data)*train_pct)\n",
    "    training_data = tensor_data[:train_end]\n",
    "    validation_data = tensor_data[train_end:]\n",
    "    return training_data, validation_data\n",
    "\n",
    "tokenizer = train_tokenizer(\"tinyshakespeare.txt\", \"tinyshakespeare_tokenizer.json\", VOCAB_SIZE)\n",
    "training_data, validation_data = tokenize_data(tokenizer, raw_data, TRAIN_PCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Bigram model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: loss = 8.420774459838867\n",
      "iter 500: loss = 8.407878875732422\n",
      "iter 1000: loss = 8.356171607971191\n",
      "iter 1500: loss = 8.379570960998535\n",
      "iter 2000: loss = 8.334782600402832\n",
      "iter 2500: loss = 8.310978889465332\n",
      "iter 3000: loss = 8.284292221069336\n",
      "iter 3500: loss = 8.290769577026367\n",
      "iter 4000: loss = 8.265420913696289\n",
      "iter 4500: loss = 8.25284481048584\n",
      "iter 5000: loss = 8.247175216674805\n",
      "iter 5500: loss = 8.199153900146484\n",
      "iter 5999: loss = 8.20830249786377\n"
     ]
    }
   ],
   "source": [
    "bigram_model = BigramLanguageModel(VOCAB_SIZE).to(device)\n",
    "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr=LR)\n",
    "bigram_model, bigram_results = train_model(\n",
    "    training_data.to(device), validation_data.to(device), bigram_model, \"bigram_model\", optimizer, \n",
    "    max_iter=MAX_ITER, batch_size=BATCH_SIZE, block_size=BLOCK_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the GPT Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: loss = 7.935868740081787\n",
      "iter 500: loss = 4.323925018310547\n",
      "iter 1000: loss = 3.9283599853515625\n",
      "iter 1500: loss = 3.7304770946502686\n"
     ]
    }
   ],
   "source": [
    "model_name = f\"gpt_model_{VOCAB_SIZE}_{BLOCK_SIZE}_{BATCH_SIZE}_{EMBD_DIM}_{MAX_ITER}_{NUM_DECODERS}_{NUM_HEADS}\"\n",
    "gpt_model = GPT(VOCAB_SIZE, BLOCK_SIZE, BATCH_SIZE, EMBD_DIM, NUM_DECODERS, NUM_HEADS).to(device)\n",
    "optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n",
    "gpt_model, gpt_results = train_model(\n",
    "    training_data.to(device), validation_data.to(device), gpt_model, model_name, optimizer, \n",
    "    max_iter=MAX_ITER, batch_size=BATCH_SIZE, block_size=BLOCK_SIZE, overwrite=False, savemodel=True \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Bigram model\n",
      "-------------------------------------\n",
      "[27, 818, 2388, 2675, 1332, 85, 1257, 2841, 1673, 1367, 2388, 728, 2389, 2110, 468, 640, 1631, 1337, 2784, 1155, 1139, 816, 1485, 1595, 2587, 1420, 1448, 144, 951, 1597, 2251, 2773, 2973, 2909, 1268, 729, 2277, 505, 562, 2993, 1215, 954, 1188, 1892, 2819, 2172, 2599, 1975, 716, 965, 2580, 1165, 2959, 1128, 898, 564, 353, 250, 1662, 1229, 1073, 2087, 106, 2683, 2245, 531, 281, 2020, 2449, 198, 1832, 379, 376, 91, 621, 2478, 2623, 2717, 738, 2447, 1409, 2845, 2423, 1156, 15, 507, 135, 1876, 1408, 1896, 2369, 1753, 1187, 316, 71, 1153, 668, 731, 1594, 986, 2715]\n",
      "OrendogstroEnglandnogodsgagedishmajestdogfordpestbitterRomeCORGentlemanGONelsmincorbessaysiedhnsadheavythisLAUIONyearidleitedcorseforcetillgreetHENRYoughsafetcommonBOLINGBROKEwantvelRATCLIFFportarmywoundskindbrialiveBAPTISTAwhisTENpleaseMENreatakBASTGRUMIOproveurchlddoorIELundencebriefenesscomebreatheULmariticedrunkWithinANTIGONprincewalkTHUMBERrayusurpsendCberENMakeUMBERedskerOPwomwhoorThidieLEONTESfurMARGARhumble\n",
      "-------------------------------------\n",
      "GPT model\n",
      "-------------------------------------\n",
      "[27, 1, 89, 1, 2247, 1, 1133, 1, 83, 1, 1073, 1, 93, 11, 96, 1, 2226, 1771, 6, 0, 1625, 1, 896, 1, 102, 1, 480, 1, 806, 1, 1777, 983, 1, 1518, 1, 80, 1, 1906, 1, 2462, 544, 1, 536, 1, 71, 1, 77, 6, 2468, 1, 1946, 1, 1363, 1, 668, 2004, 1160, 1, 2155, 0, 1798, 1, 624, 1, 2376, 1, 1146, 1, 273, 1, 838, 6, 1, 373, 1, 70, 1, 888, 7, 2347, 880, 2560, 202, 1, 503, 744, 1, 258, 1, 113, 1477, 2448, 1, 2972, 206, 860, 225, 1, 52, 1273, 1]\n",
      "O of Swe sure you prove be;my braceWel,\n",
      "work none as VINCENTIO LUCIO heavensfal wise to virtue concefl pray or st,quo frown together diesumrather GAUNT\n",
      "become Than seal country their thine, hand the why-naturalWICdoubleown emors can deingbrokeyond itestamasterble nLAND \n"
     ]
    }
   ],
   "source": [
    "starting_text = \"O Romeo, Romeo, wherefore art thou Romeo?\"\n",
    "starting_tokens = tokenizer.encode(starting_text).ids\n",
    "starting_tokens = torch.tensor(starting_tokens, dtype=torch.long).reshape(-1,1)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Bigram model\")\n",
    "print(\"-------------------------------------\")\n",
    "gen_tokens = bigram_model.generate(curr_tokens = starting_tokens.to(device), num_gen_tokens = 100)[0].tolist()\n",
    "print(gen_tokens)\n",
    "print(tokenizer.decode(gen_tokens))\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"GPT model\")\n",
    "print(\"-------------------------------------\")\n",
    "gen_tokens = gpt_model.generate(curr_tokens = starting_tokens.to(device), num_gen_tokens = 100)[0].tolist()\n",
    "print(gen_tokens)\n",
    "print(tokenizer.decode(gen_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the training loss and the validation loss for each iteration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpt_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m plt.plot(bigram_results[\u001b[33m\"\u001b[39m\u001b[33miters\u001b[39m\u001b[33m\"\u001b[39m], bigram_results[\u001b[33m\"\u001b[39m\u001b[33mtraining_loss\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mBigram Training Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m plt.plot(bigram_results[\u001b[33m\"\u001b[39m\u001b[33miters\u001b[39m\u001b[33m\"\u001b[39m], bigram_results[\u001b[33m\"\u001b[39m\u001b[33mvalidation_loss\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mBigram Validation Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m--\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[43mgpt_results\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33miters\u001b[39m\u001b[33m\"\u001b[39m], gpt_results[\u001b[33m\"\u001b[39m\u001b[33mtraining_loss\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mGPT Training Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m plt.plot(gpt_results[\u001b[33m\"\u001b[39m\u001b[33miters\u001b[39m\u001b[33m\"\u001b[39m], gpt_results[\u001b[33m\"\u001b[39m\u001b[33mvalidation_loss\u001b[39m\u001b[33m\"\u001b[39m], label=\u001b[33m\"\u001b[39m\u001b[33mGPT Validation Loss\u001b[39m\u001b[33m\"\u001b[39m, color=\u001b[33m\"\u001b[39m\u001b[33mred\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Labels and title\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'gpt_results' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(bigram_results[\"iters\"], bigram_results[\"training_loss\"], label=\"Bigram Training Loss\", color=\"blue\", linestyle=\"--\")\n",
    "plt.plot(bigram_results[\"iters\"], bigram_results[\"validation_loss\"], label=\"Bigram Validation Loss\", color=\"red\", linestyle=\"--\")\n",
    "plt.plot(gpt_results[\"iters\"], gpt_results[\"training_loss\"], label=\"GPT Training Loss\", color=\"blue\", linestyle=\"-\")\n",
    "plt.plot(gpt_results[\"iters\"], gpt_results[\"validation_loss\"], label=\"GPT Validation Loss\", color=\"red\", linestyle=\"-\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Estimated Cross Entropy Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform a grid search to find the best parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Training model gpt_model_1500_8_32_24_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_32_24_2000_6_12\" already exists. Skipping training...\n",
      "Model0 perplexity is: 201.2358702697754\n",
      "Training model gpt_model_1500_8_32_24_2000_12_12\n",
      "Model file of \"gpt_model_1500_8_32_24_2000_12_12\" already exists. Skipping training...\n",
      "Model1 perplexity is: 198.89654336547852\n",
      "Training model gpt_model_1500_8_32_48_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_32_48_2000_6_12\" already exists. Skipping training...\n",
      "Model2 perplexity is: 89.22371969604492\n",
      "Training model gpt_model_1500_8_32_48_2000_12_12\n",
      "Model file of \"gpt_model_1500_8_32_48_2000_12_12\" already exists. Skipping training...\n",
      "Model3 perplexity is: 99.56676547241211\n",
      "Training model gpt_model_1500_8_32_96_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_32_96_2000_6_12\" already exists. Skipping training...\n",
      "Model4 perplexity is: 61.11876518249512\n",
      "Training model gpt_model_1500_8_32_96_2000_12_12\n",
      "Model file of \"gpt_model_1500_8_32_96_2000_12_12\" already exists. Skipping training...\n",
      "Model5 perplexity is: 62.00362856292725\n",
      "Training model gpt_model_1500_8_64_24_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_64_24_2000_6_12\" already exists. Skipping training...\n",
      "Model6 perplexity is: 214.22317379760742\n",
      "Training model gpt_model_1500_8_64_24_2000_12_12\n",
      "Model file of \"gpt_model_1500_8_64_24_2000_12_12\" already exists. Skipping training...\n",
      "Model7 perplexity is: 202.79811022949218\n",
      "Training model gpt_model_1500_8_64_48_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_64_48_2000_6_12\" already exists. Skipping training...\n",
      "Model8 perplexity is: 88.68495819091797\n",
      "Training model gpt_model_1500_8_64_48_2000_12_12\n",
      "Model file of \"gpt_model_1500_8_64_48_2000_12_12\" already exists. Skipping training...\n",
      "Model9 perplexity is: 87.06414735412598\n",
      "Training model gpt_model_1500_8_64_96_2000_6_12\n",
      "Model file of \"gpt_model_1500_8_64_96_2000_6_12\" already exists. Skipping training...\n",
      "Model10 perplexity is: 58.507169021606444\n",
      "Training model gpt_model_1500_8_64_96_2000_12_12\n",
      "iter 0: loss = 7.479243278503418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[362]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     28\u001b[39m gpt_model = GPT(vocab_size, block_size, batch_size, embd_dim, num_decoder, num_head).to(device)\n\u001b[32m     29\u001b[39m optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m gpt_model, gpt_results = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavemodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m perplexity is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpt_results[\u001b[33m\"\u001b[39m\u001b[33mperplexity\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#clear_output(wait=True)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[343]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_set, validation_set, model, model_name, optimizer, max_iter, batch_size, block_size, overwrite, savemodel)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Estimate and save the training loss and validation loss\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     training_loss = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m     validation_loss = estimate_loss(model, validation_set, batch_size, block_size, \u001b[32m500\u001b[39m)\n\u001b[32m     87\u001b[39m     training_losses.append(training_loss.item())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[265]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m(model, data, batch_size, block_size, iters)\u001b[39m\n\u001b[32m      6\u001b[39m     inputs, outputs = get_batch(data, batch_size, block_size)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m         logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     losses[k] = loss.item()\n\u001b[32m     10\u001b[39m mean_loss = losses.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[319]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mGPT.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m     20\u001b[39m pos_emb = \u001b[38;5;28mself\u001b[39m.position_embedding_table(torch.arange(T, device=device)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[32m     21\u001b[39m inputs = tok_emb + pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.linear_layer(inputs)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:613\u001b[39m, in \u001b[36mTransformerDecoder.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    610\u001b[39m tgt_is_causal = _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    625\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.norm(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1116\u001b[39m, in \u001b[36mTransformerDecoderLayer.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m   1107\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m   1108\u001b[39m         x + \u001b[38;5;28mself\u001b[39m._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[32m   1109\u001b[39m     )\n\u001b[32m   1110\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(\n\u001b[32m   1111\u001b[39m         x\n\u001b[32m   1112\u001b[39m         + \u001b[38;5;28mself\u001b[39m._mha_block(\n\u001b[32m   1113\u001b[39m             x, memory, memory_mask, memory_key_padding_mask, memory_is_causal\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1116\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm3(x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1161\u001b[39m, in \u001b[36mTransformerDecoderLayer._ff_block\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.linear2(\u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.activation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[32m   1162\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "block_sizes = [8, 16]\n",
    "batch_sizes = [32]\n",
    "max_iters = [2000]\n",
    "vocab_sizes = [1500]\n",
    "embd_dims = [24, 48, 96]\n",
    "num_decoders = [6, 12]\n",
    "num_heads = [12]\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Estimated Cross Entropy Loss\")\n",
    "ax.set_title(\"Training vs Validation Loss\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Perplexity\")\n",
    "ax2.set_title(\"Training vs Validation Loss\")\n",
    "ax2.grid(True)\n",
    "\n",
    "iter = 0\n",
    "for vocab_size in vocab_sizes:\n",
    "    tokenizers = [train_tokenizer(\"tinyshakespeare.txt\", \"tinyshakespeare_tokenizer.json\", vocab_size), GPT2Tokenizer.from_pretrained(\"gpt2\")]\n",
    "    for tokenizer in tokenizers:\n",
    "        training_data, validation_data = tokenize_data(tokenizer, raw_data, TRAIN_PCT)\n",
    "        for block_size in block_sizes:\n",
    "            for batch_size in batch_sizes:\n",
    "                for max_iter in max_iters:\n",
    "                    for embd_dim in embd_dims:\n",
    "                        for num_decoder in num_decoders:\n",
    "                            for num_head in num_heads:\n",
    "                                model_name = f\"gpt_model_{vocab_size}_{block_size}_{batch_size}_{embd_dim}_{max_iter}_{num_decoder}_{num_head}\"\n",
    "                                print(f\"Training model {model_name}\")\n",
    "                                gpt_model = GPT(vocab_size, block_size, batch_size, embd_dim, num_decoder, num_head).to(device)\n",
    "                                optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n",
    "                                gpt_model, gpt_results = train_model(\n",
    "                                    training_data.to(device), validation_data.to(device), gpt_model, model_name, optimizer, \n",
    "                                    max_iter=max_iter, batch_size=batch_size, block_size=block_size, overwrite=False, savemodel=True \n",
    "                                )\n",
    "                                clear_output(wait=True)\n",
    "                                rand_color = \"C\" + str(iter)\n",
    "                                ax.plot(gpt_results[\"iters\"], gpt_results[\"training_loss\"], label=f\"Model{iter} Training Loss\", color=rand_color, linestyle=\"-\")\n",
    "                                ax.plot(gpt_results[\"iters\"], gpt_results[\"validation_loss\"], label=f\"Model{iter} Validation Loss\", color=rand_color, linestyle=\"--\")\n",
    "                                ax.relim()  # Recalculate limits\n",
    "                                ax.autoscale_view()  # Autoscale based on new limits\n",
    "                                ax.legend()\n",
    "                                ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "                                ax2.bar(f\"Model{iter}\", gpt_results[\"perplexity\"])\n",
    "                                display(fig)\n",
    "                                display(fig2)\n",
    "                                plt.close(fig)\n",
    "                                plt.close(fig2)\n",
    "                                iter += 1\n",
    "\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BML_GPT_mac)",
   "language": "python",
   "name": "bml_gpt_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
