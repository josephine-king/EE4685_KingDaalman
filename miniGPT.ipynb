{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EE4685 Assignment 2: Building a miniGPT** by Josephine King and Alec Daalman\n",
    "\n",
    "**References:**\n",
    "- \"Let's build GPT: from scratch, in code, spelled out.\" Youtube tutorial by Andrej Karpathy. https://www.youtube.com/watch?v=kCc8FmEb1nY\n",
    "- HuggingFace Tokenizer developer guides. https://huggingface.co/docs/transformers/en/notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "--2025-03-24 13:38:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘tinyshakespeare.txt’\n",
      "\n",
      "tinyshakespeare.txt 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-03-24 13:38:56 (25.9 MB/s) - ‘tinyshakespeare.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "#from tqdm.notebook import tqdm\n",
    "#import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as data\n",
    "from tokenizers import Tokenizer, pre_tokenizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.decoders import BPEDecoder\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from torchmetrics.text import Perplexity\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "run_on_colab = False\n",
    "\n",
    "# Setup\n",
    "torch.manual_seed(6250513)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "# Set up file saving on google drive\n",
    "if (run_on_colab):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    # Create a folder in the root directory\n",
    "    !mkdir -p \"/content/drive/saved_models\"\n",
    "    CHECKPOINT_PATH = \"/content/drive/saved_models/\"\n",
    "else:\n",
    "    CHECKPOINT_PATH = \"./saved_models/\"\n",
    "\n",
    "# Initialize model parameters\n",
    "TRAIN_PCT = 0.8\n",
    "VOCAB_SIZE = 1500\n",
    "LR = 2.5e-4\n",
    "\n",
    "# Download the TinyShakespeare dataset\n",
    "!wget -O tinyshakespeare.txt https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('tinyshakespeare.txt', 'r', encoding='utf-8') as f: raw_data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPT Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT architecture \n",
    "class GPT(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, block_size, batch_size, embd_dim, decoders, num_heads):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embd_dim)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, embd_dim)\n",
    "\n",
    "        self.transformer_blocks = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=embd_dim, nhead=num_heads, dim_feedforward=3072, dropout=0.1), decoders, norm=None)\n",
    "        self.linear_layer = nn.Linear(embd_dim, vocab_size)\n",
    "        self.block_size = block_size\n",
    "\n",
    "        self.config = {\"vocab_size\": vocab_size, \"block_size\": block_size, \"batch_size\": batch_size, \"embd_dim\": embd_dim, \"decoders\": decoders, \"num_heads\": num_heads}\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        B, T = idx.shape\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        inputs = tok_emb + pos_emb # (B,T,C)\n",
    "        inputs = self.transformer_blocks(inputs, memory=torch.zeros_like(inputs))\n",
    "        logits = self.linear_layer(inputs)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # Generate num_gen_tokens more tokens given the current tokens in curr_tokens\n",
    "    def generate(self, curr_tokens, num_gen_tokens):\n",
    "        for _ in range(num_gen_tokens):\n",
    "            curr_tokens_cond = curr_tokens[:, -self.block_size:]\n",
    "            # Get the predictions for the next tokens \n",
    "            preds, loss = self.forward(curr_tokens_cond)\n",
    "            # Look only at the last time step\n",
    "            preds = preds[:, -1, :] # becomes (B, C)\n",
    "            # Normalize probabilities from 0 to 1 using softmax\n",
    "            probs = F.softmax(preds, dim=-1) # (B, C)\n",
    "            # Get the next token by sampling from the probability distribution\n",
    "            next_token = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # Add the new token to the current tokens\n",
    "            curr_tokens = torch.cat((curr_tokens, next_token), dim=1) # (B, T+1)\n",
    "        return curr_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Helper/Evaluation Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(data, batch_size, block_size):\n",
    "    # Choose batch_size random starting points\n",
    "    block_starts = torch.randint(0, len(data) - block_size, (batch_size,))\n",
    "    # Get the inputs and outputs for the chosen blocks, stack them into tensors\n",
    "    batch_inputs = torch.stack([data[start: start + block_size] for start in block_starts])\n",
    "    batch_outputs = torch.stack([data[start + 1: start + block_size + 1] for start in block_starts])\n",
    "    return batch_inputs, batch_outputs\n",
    "\n",
    "def estimate_loss(model, data, batch_size, block_size, iters):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    losses = torch.zeros(iters)\n",
    "    for k in range(iters):\n",
    "        inputs, outputs = get_batch(data, batch_size, block_size)\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(inputs, outputs)\n",
    "        losses[k] = loss.item()\n",
    "    mean_loss = losses.mean()\n",
    "    model.train()\n",
    "    return mean_loss\n",
    "\n",
    "def calculate_perplexity(model, validation_data, num_batch, batch_size, block_size):\n",
    "    perplexities = []\n",
    "    for i in range(0, num_batch):\n",
    "        inputs, outputs = get_batch(validation_data, batch_size, block_size)\n",
    "        with torch.no_grad():\n",
    "            logits, loss = model(inputs)\n",
    "\n",
    "        perplexity = Perplexity().to(device)\n",
    "        score = perplexity(preds=logits[:, :-1], target=inputs[:, 1:]) \n",
    "        perplexities.append(score.item())\n",
    "\n",
    "    return np.mean(perplexities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training Functions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions are adapted from the optimization exercise \n",
    "def _get_config_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \".config\")\n",
    "\n",
    "def _get_model_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \".tar\")\n",
    "\n",
    "def _get_result_file(model_path, model_name):\n",
    "    return os.path.join(model_path, model_name + \"_results.json\")\n",
    "\n",
    "def save_model(model, model_path, model_name, model_result):\n",
    "    config_dict = model.config\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    config_file, model_file, result_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name), _get_result_file(model_path, model_name)\n",
    "    with open(config_file, \"w\") as f:\n",
    "        json.dump(config_dict, f)\n",
    "    with open(result_file, \"w\") as f:\n",
    "        json.dump(model_result, f)\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "\n",
    "def load_model(model_path, model_name):\n",
    "    config_file, model_file, result_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name), _get_result_file(model_path, model_name)\n",
    "    with open(config_file, \"r\") as f:\n",
    "        config_dict = json.load(f)\n",
    "\n",
    "    model = GPT(config_dict[\"vocab_size\"], config_dict[\"block_size\"], config_dict[\"batch_size\"], config_dict[\"embd_dim\"], config_dict[\"decoders\"], config_dict[\"num_heads\"])\n",
    "    model.load_state_dict(torch.load(model_file, map_location=torch.device(device)))    \n",
    "    \n",
    "    with open(result_file, \"r\") as f:\n",
    "        model_result = json.load(f)\n",
    "\n",
    "    return model, model_result\n",
    "\n",
    "def train_model(train_set, validation_set, model, model_name, optimizer, max_iter=1000, batch_size=256, block_size=32, overwrite=False, savemodel=False):\n",
    "    \"\"\"\n",
    "    Train a model on the training set of FashionMNIST\n",
    "\n",
    "    Inputs:\n",
    "        train_set - Training dataset\n",
    "        validation_set - Validation dataset\n",
    "        model - nn.Module object\n",
    "        model_name - Name of the model\n",
    "        max_iter - Number of iterations we want to (maximally) train for\n",
    "        batch_size - Size of batches used in training\n",
    "        overwrite - Determines if we should overwrite pre-existing models\n",
    "        savemodel - Whether or not we should save the model to a file\n",
    "    \"\"\"\n",
    "    # Check if the model already exists\n",
    "    # If it does and we are not overwriting, load it from the file\n",
    "    # If it doesn't, train the model\n",
    "    file_exists = os.path.isfile(_get_model_file(CHECKPOINT_PATH, model_name))\n",
    "    if file_exists and not overwrite:\n",
    "        print(f\"Model file of \\\"{model_name}\\\" already exists. Skipping training...\")\n",
    "        model, results = load_model(CHECKPOINT_PATH, model_name)\n",
    "    else:\n",
    "        if file_exists:\n",
    "            print(\"Model file exists, but will be overwritten...\")\n",
    "\n",
    "        # Training the model\n",
    "        training_losses = []\n",
    "        validation_losses = []\n",
    "        iters = []\n",
    "        iter_times = []\n",
    "        results = {}\n",
    "        model.train()\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_iter)\n",
    "        \n",
    "        for iter in range(max_iter):\n",
    "            start_time = time.time()\n",
    "            inputs, outputs = get_batch(train_set, batch_size, block_size)\n",
    "            inputs, outputs = inputs.to(device), outputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds,loss = model(inputs, outputs)\n",
    "\n",
    "            # Printing \n",
    "            if iter % 50 == 0 or iter == max_iter - 1:\n",
    "                print(f\"iter {iter}: loss = {loss}\")\n",
    "\n",
    "            # Estimate and save the training loss and validation loss\n",
    "            if (iter % 50 == 0):\n",
    "                training_loss = estimate_loss(model, train_set, batch_size, block_size, 500)\n",
    "                validation_loss = estimate_loss(model, validation_set, batch_size, block_size, 500)\n",
    "                training_losses.append(training_loss.item())\n",
    "                validation_losses.append(validation_loss.item())\n",
    "                iters.append(iter)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            iter_times.append(time.time() - start_time)\n",
    "\n",
    "        # Calculate the perplexity and save results to the dict\n",
    "        perplexity = calculate_perplexity(model, validation_set, 500, batch_size, block_size)\n",
    "        results[\"perplexity\"] = perplexity\n",
    "        results[\"iters\"] = iters\n",
    "        results[\"training_loss\"] = training_losses\n",
    "        results[\"validation_loss\"] = validation_losses\n",
    "        results[\"avg_time_per_iter\"] = np.mean(iter_times)\n",
    "        results[\"total_params\"] = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "        # Save the model to a file\n",
    "        if (savemodel):\n",
    "            save_model(model, CHECKPOINT_PATH, model_name, results)\n",
    "            \n",
    "    torch.cuda.empty_cache()\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preprocessing**\n",
    "\n",
    "Create a custom tokenizer using the HuggingFace Tokenizer package. Then encode the data, convert it into a PyTorch tensor, and split it up into validation data and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the tokenizer \n",
    "def train_tokenizer(train_file_name, save_file_name, vocab_size):\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\")) \n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Sequence([pre_tokenizers.Punctuation(\"isolated\"), pre_tokenizers.Split(\"\\n\", \"isolated\"), pre_tokenizers.Split(\" \", \"isolated\")])\n",
    "    trainer = BpeTrainer(vocab_size=vocab_size)\n",
    "    tokenizer.decoder = BPEDecoder()\n",
    "    tokenizer.train([train_file_name], trainer)\n",
    "    tokenizer.save(save_file_name)\n",
    "    return tokenizer\n",
    "\n",
    "# Load a pre-existing tokenizer\n",
    "def load_tokenizer(file_name):\n",
    "    tokenizer = Tokenizer.from_file(file_name)\n",
    "\n",
    "# Tokenize the data\n",
    "def tokenize_data(tok, tokenizer, raw_data, train_pct):\n",
    "    if tok == \"GPT2\":\n",
    "        tokenized_data = tokenizer.encode(raw_data)\n",
    "    else:\n",
    "        tokenized_data = tokenizer.encode(raw_data).ids\n",
    "    # Convert into a pytorch tensor\n",
    "    tensor_data = torch.tensor(tokenized_data, dtype=torch.long)\n",
    "    # Split into training and validation sets\n",
    "    train_end = int(len(tensor_data)*train_pct)\n",
    "    training_data = tensor_data[:train_end]\n",
    "    validation_data = tensor_data[train_end:]\n",
    "    return training_data, validation_data\n",
    "\n",
    "tokenizer = train_tokenizer(\"tinyshakespeare.txt\", \"tinyshakespeare_tokenizer.json\", VOCAB_SIZE)\n",
    "training_data, validation_data = tokenize_data(\"custom\", tokenizer, raw_data, TRAIN_PCT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform a grid search to find the best parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Training model gpt_model_1500_128_32_192_1000_12_12\n",
      "iter 0: loss = 7.5009765625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[419]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m gpt_model = GPT(vocab_size, block_size, batch_size, embd_dim, num_decoder, num_head).to(device)\n\u001b[32m     49\u001b[39m optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m gpt_model, gpt_results = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpt_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavemodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m clear_output(wait=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     55\u001b[39m rand_color = \u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28miter\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[416]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(train_set, validation_set, model, model_name, optimizer, max_iter, batch_size, block_size, overwrite, savemodel)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# Estimate and save the training loss and validation loss\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     training_loss = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     validation_loss = estimate_loss(model, validation_set, batch_size, block_size, \u001b[32m500\u001b[39m)\n\u001b[32m     82\u001b[39m     training_losses.append(training_loss.item())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[415]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m(model, data, batch_size, block_size, iters)\u001b[39m\n\u001b[32m     14\u001b[39m     inputs, outputs = get_batch(data, batch_size, block_size)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m         logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     losses[k] = loss.item()\n\u001b[32m     18\u001b[39m mean_loss = losses.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[402]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mGPT.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m     20\u001b[39m pos_emb = \u001b[38;5;28mself\u001b[39m.position_embedding_table(torch.arange(T, device=device)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[32m     21\u001b[39m inputs = tok_emb + pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m inputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.linear_layer(inputs)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:613\u001b[39m, in \u001b[36mTransformerDecoder.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m    610\u001b[39m tgt_is_causal = _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     output = \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    625\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.norm(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1112\u001b[39m, in \u001b[36mTransformerDecoderLayer.forward\u001b[39m\u001b[34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[39m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1107\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm1(\n\u001b[32m   1108\u001b[39m         x + \u001b[38;5;28mself\u001b[39m._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[32m   1109\u001b[39m     )\n\u001b[32m   1110\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm2(\n\u001b[32m   1111\u001b[39m         x\n\u001b[32m-> \u001b[39m\u001b[32m1112\u001b[39m         + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.norm3(x + \u001b[38;5;28mself\u001b[39m._ff_block(x))\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/transformer.py:1148\u001b[39m, in \u001b[36mTransformerDecoderLayer._mha_block\u001b[39m\u001b[34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[39m\n\u001b[32m   1140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mha_block\u001b[39m(\n\u001b[32m   1141\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1142\u001b[39m     x: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1146\u001b[39m     is_causal: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1147\u001b[39m ) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1148\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m   1157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dropout2(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/modules/activation.py:1373\u001b[39m, in \u001b[36mMultiheadAttention.forward\u001b[39m\u001b[34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   1347\u001b[39m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[32m   1348\u001b[39m         query,\n\u001b[32m   1349\u001b[39m         key,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1370\u001b[39m         is_causal=is_causal,\n\u001b[32m   1371\u001b[39m     )\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     attn_output, attn_output_weights = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m), attn_output_weights\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/BML_GPT/lib/python3.12/site-packages/torch/nn/functional.py:6410\u001b[39m, in \u001b[36mmulti_head_attention_forward\u001b[39m\u001b[34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[39m\n\u001b[32m   6407\u001b[39m k = k.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m   6408\u001b[39m v = v.view(bsz, num_heads, src_len, head_dim)\n\u001b[32m-> \u001b[39m\u001b[32m6410\u001b[39m attn_output = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\n\u001b[32m   6412\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6413\u001b[39m attn_output = (\n\u001b[32m   6414\u001b[39m     attn_output.permute(\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m).contiguous().view(bsz * tgt_len, embed_dim)\n\u001b[32m   6415\u001b[39m )\n\u001b[32m   6417\u001b[39m attn_output = linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loop_decoders = True\n",
    "loop_embd_dims = False\n",
    "\n",
    "block_sizes = [128]\n",
    "batch_sizes = [32]\n",
    "max_iters = [500]\n",
    "vocab_sizes = [1500]\n",
    "embd_dims = [192]\n",
    "num_decoders = [12]\n",
    "num_heads = [12]\n",
    "tokenizers = [\"custom\"]\n",
    "\n",
    "if (loop_decoders == True):\n",
    "    num_decoders = [12, 24, 36]\n",
    "if (loop_embd_dims == True):\n",
    "    embd_dims = [192, 384, 768]\n",
    "\n",
    "# Set up plotting\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel(\"Iterations\")\n",
    "ax.set_ylabel(\"Estimated Cross Entropy Loss\")\n",
    "ax.set_title(\"Training and Validation Loss\")\n",
    "ax.grid(True)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.set_xlabel(\"Iterations\")\n",
    "ax2.set_ylabel(\"Perplexity\")\n",
    "ax2.set_title(\"Perplexity\")\n",
    "ax2.grid(True)\n",
    "\n",
    "# Loop through parameters and train model \n",
    "iter = 0\n",
    "for vocab_size in vocab_sizes:\n",
    "    for tok in tokenizers:\n",
    "        if tok == \"GPT2\":\n",
    "            tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "            vocab_size = tokenizer.vocab_size\n",
    "        else:\n",
    "            tokenizer = train_tokenizer(\"tinyshakespeare.txt\", \"tinyshakespeare_tokenizer.json\", vocab_size)\n",
    "        training_data, validation_data = tokenize_data(tok, tokenizer, raw_data, TRAIN_PCT)\n",
    "        for block_size in block_sizes:\n",
    "            for batch_size in batch_sizes:\n",
    "                for max_iter in max_iters:\n",
    "                    for embd_dim in embd_dims:\n",
    "                        for num_decoder in num_decoders:\n",
    "                            for num_head in num_heads:\n",
    "                                # Train the model\n",
    "                                model_name = f\"gpt_model_{vocab_size}_{block_size}_{batch_size}_{embd_dim}_{max_iter}_{num_decoder}_{num_head}\"\n",
    "                                print(f\"Training model {model_name}\")\n",
    "                                gpt_model = GPT(vocab_size, block_size, batch_size, embd_dim, num_decoder, num_head).to(device)\n",
    "                                optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n",
    "                                gpt_model, gpt_results = train_model(\n",
    "                                    training_data.to(device), validation_data.to(device), gpt_model, model_name, optimizer, \n",
    "                                    max_iter=max_iter, batch_size=batch_size, block_size=block_size, overwrite=False, savemodel=True \n",
    "                                )\n",
    "                                # Plotting\n",
    "                                clear_output(wait=True)\n",
    "                                rand_color = \"C\" + str(iter)\n",
    "                                ax.plot(gpt_results[\"iters\"], gpt_results[\"training_loss\"], label=f\"Model{iter} Training Loss\", color=rand_color, linestyle=\"-\")\n",
    "                                ax.plot(gpt_results[\"iters\"], gpt_results[\"validation_loss\"], label=f\"Model{iter} Validation Loss\", color=rand_color, linestyle=\"--\")\n",
    "                                ax.relim()  # Recalculate limits\n",
    "                                ax.autoscale_view()  # Autoscale based on new limits\n",
    "                                ax.legend()\n",
    "                                ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "                                ax2.bar(f\"Model{iter}\", gpt_results[\"perplexity\"])\n",
    "                                display(fig)\n",
    "                                display(fig2)\n",
    "                                plt.close(fig)\n",
    "                                plt.close(fig2)\n",
    "                                iter += 1\n",
    "    if tok == \"GPT2\":\n",
    "        break\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate text with the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file exists, but will be overwritten...\n",
      "iter 0: loss = 7.559665679931641\n",
      "iter 499: loss = 5.9153947830200195\n",
      "-------------------------------------\n",
      "GPT model\n",
      "-------------------------------------\n",
      "Model parameters: 193860\n",
      "Average time per iteration: 0.05867657995223999\n",
      "Perplexity: 390.7777250366211\n",
      "OTywrThennaturerow POMisbetterwnsenct perboyofzThyhavegoodselvesPOMolhas$anceranceKaterommapaunesYhasteENsentoseore'engcityISABELLAhaveProvostfaircoldARDComMeeechSonceclOMHenryULINA3oIETbutWARWICKmyWecentWeROdear ThatsubaskinglessenghandHORTENPetBUCMENENIUSornGooderyitsyoujoyuckAUTOLYCUSowctIVentpastetnowINAengjethinksgotdown\n"
     ]
    }
   ],
   "source": [
    "vocab_size = VOCAB_SIZE\n",
    "block_size = 8\n",
    "batch_size = 32\n",
    "embd_dim = 12\n",
    "max_iter = 500\n",
    "num_decoders = 2\n",
    "num_heads = 6\n",
    "\n",
    "model_name = f\"gpt_model_{vocab_size}_{block_size}_{batch_size}_{embd_dim}_{max_iter}_{num_decoders}_{num_heads}\"\n",
    "gpt_model = GPT(vocab_size, block_size, batch_size, embd_dim, num_decoders, NUM_HEADS).to(device)\n",
    "optimizer = torch.optim.AdamW(gpt_model.parameters(), lr=LR)\n",
    "gpt_model, gpt_results = train_model(\n",
    "    training_data.to(device), validation_data.to(device), gpt_model, model_name, optimizer, \n",
    "    max_iter=max_iter, batch_size=batch_size, block_size=block_size, overwrite=False, savemodel=True \n",
    ")\n",
    "\n",
    "starting_text = \"O Romeo, Romeo, wherefore art thou Romeo?\"\n",
    "starting_tokens = tokenizer.encode(starting_text).ids\n",
    "starting_tokens = torch.tensor(starting_tokens, dtype=torch.long).reshape(-1,1)\n",
    "gen_tokens = gpt_model.generate(curr_tokens = starting_tokens.to(device), num_gen_tokens = 100)[0].tolist()\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "print(\"GPT model\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Model parameters: {gpt_results[\"total_params\"]}\")\n",
    "print(f\"Average time per iteration: {gpt_results[\"avg_time_per_iter\"]}\")\n",
    "print(f\"Perplexity: {gpt_results[\"perplexity\"]}\")\n",
    "print(tokenizer.decode(gen_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BML_GPT_mac)",
   "language": "python",
   "name": "bml_gpt_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
